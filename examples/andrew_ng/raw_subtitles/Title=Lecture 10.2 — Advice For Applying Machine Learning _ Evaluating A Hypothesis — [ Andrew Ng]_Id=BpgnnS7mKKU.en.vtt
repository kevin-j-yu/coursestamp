WEBVTT
Kind: captions
Language: en

00:00:00.060 --> 00:00:02.180 align:start position:0%
 
in<00:00:00.240><c> this</c><00:00:00.450><c> video</c><00:00:00.810><c> I'd</c><00:00:01.110><c> like</c><00:00:01.290><c> to</c><00:00:01.410><c> talk</c><00:00:01.589><c> about</c><00:00:01.800><c> how</c>

00:00:02.180 --> 00:00:02.190 align:start position:0%
in this video I'd like to talk about how
 

00:00:02.190 --> 00:00:05.059 align:start position:0%
in this video I'd like to talk about how
to<00:00:02.250><c> evaluate</c><00:00:02.639><c> a</c><00:00:03.480><c> hypothesis</c><00:00:04.350><c> that</c><00:00:04.380><c> has</c><00:00:04.650><c> been</c>

00:00:05.059 --> 00:00:05.069 align:start position:0%
to evaluate a hypothesis that has been
 

00:00:05.069 --> 00:00:07.400 align:start position:0%
to evaluate a hypothesis that has been
learned<00:00:05.339><c> by</c><00:00:05.549><c> your</c><00:00:05.879><c> algorithm</c><00:00:06.420><c> in</c><00:00:07.020><c> later</c>

00:00:07.400 --> 00:00:07.410 align:start position:0%
learned by your algorithm in later
 

00:00:07.410 --> 00:00:09.650 align:start position:0%
learned by your algorithm in later
videos<00:00:07.919><c> we'll</c><00:00:08.189><c> build</c><00:00:08.490><c> on</c><00:00:08.700><c> this</c><00:00:08.880><c> to</c><00:00:09.090><c> talk</c><00:00:09.630><c> about</c>

00:00:09.650 --> 00:00:09.660 align:start position:0%
videos we'll build on this to talk about
 

00:00:09.660 --> 00:00:11.810 align:start position:0%
videos we'll build on this to talk about
how<00:00:10.139><c> to</c><00:00:10.200><c> prevent</c><00:00:10.740><c> the</c><00:00:11.010><c> problems</c><00:00:11.550><c> of</c>

00:00:11.810 --> 00:00:11.820 align:start position:0%
how to prevent the problems of
 

00:00:11.820 --> 00:00:15.160 align:start position:0%
how to prevent the problems of
overfitting<00:00:12.420><c> and</c><00:00:12.719><c> underfitting</c><00:00:12.840><c> as</c><00:00:13.650><c> well</c>

00:00:15.160 --> 00:00:15.170 align:start position:0%
overfitting and underfitting as well
 

00:00:15.170 --> 00:00:17.930 align:start position:0%
overfitting and underfitting as well
when<00:00:16.170><c> we</c><00:00:16.320><c> fit</c><00:00:16.560><c> the</c><00:00:16.680><c> parameters</c><00:00:16.890><c> of</c><00:00:17.699><c> our</c>

00:00:17.930 --> 00:00:17.940 align:start position:0%
when we fit the parameters of our
 

00:00:17.940 --> 00:00:19.670 align:start position:0%
when we fit the parameters of our
learning<00:00:18.210><c> algorithm</c><00:00:18.840><c> we</c><00:00:19.140><c> think</c><00:00:19.380><c> about</c>

00:00:19.670 --> 00:00:19.680 align:start position:0%
learning algorithm we think about
 

00:00:19.680 --> 00:00:22.070 align:start position:0%
learning algorithm we think about
choosing<00:00:20.039><c> the</c><00:00:20.310><c> parameters</c><00:00:20.939><c> to</c><00:00:21.330><c> minimize</c><00:00:21.840><c> the</c>

00:00:22.070 --> 00:00:22.080 align:start position:0%
choosing the parameters to minimize the
 

00:00:22.080 --> 00:00:24.230 align:start position:0%
choosing the parameters to minimize the
training<00:00:22.529><c> error</c><00:00:22.710><c> one</c><00:00:23.519><c> might</c><00:00:23.699><c> think</c><00:00:23.730><c> that</c>

00:00:24.230 --> 00:00:24.240 align:start position:0%
training error one might think that
 

00:00:24.240 --> 00:00:26.450 align:start position:0%
training error one might think that
getting<00:00:24.660><c> a</c><00:00:24.869><c> really</c><00:00:25.170><c> low</c><00:00:25.380><c> value</c><00:00:25.859><c> of</c><00:00:26.070><c> training</c>

00:00:26.450 --> 00:00:26.460 align:start position:0%
getting a really low value of training
 

00:00:26.460 --> 00:00:28.339 align:start position:0%
getting a really low value of training
error<00:00:26.609><c> might</c><00:00:26.939><c> be</c><00:00:27.090><c> a</c><00:00:27.119><c> good</c><00:00:27.390><c> thing</c><00:00:27.660><c> though</c><00:00:28.170><c> we've</c>

00:00:28.339 --> 00:00:28.349 align:start position:0%
error might be a good thing though we've
 

00:00:28.349 --> 00:00:30.140 align:start position:0%
error might be a good thing though we've
already<00:00:28.529><c> seen</c><00:00:29.010><c> that</c><00:00:29.400><c> just</c><00:00:29.760><c> because</c><00:00:30.029><c> the</c>

00:00:30.140 --> 00:00:30.150 align:start position:0%
already seen that just because the
 

00:00:30.150 --> 00:00:32.569 align:start position:0%
already seen that just because the
hypothesis<00:00:30.869><c> has</c><00:00:31.170><c> low</c><00:00:31.380><c> training</c><00:00:31.679><c> error</c><00:00:31.920><c> that</c>

00:00:32.569 --> 00:00:32.579 align:start position:0%
hypothesis has low training error that
 

00:00:32.579 --> 00:00:34.190 align:start position:0%
hypothesis has low training error that
doesn't<00:00:33.030><c> mean</c><00:00:33.180><c> it's</c><00:00:33.420><c> necessarily</c><00:00:33.600><c> a</c><00:00:33.989><c> good</c>

00:00:34.190 --> 00:00:34.200 align:start position:0%
doesn't mean it's necessarily a good
 

00:00:34.200 --> 00:00:36.530 align:start position:0%
doesn't mean it's necessarily a good
hypothesis<00:00:34.920><c> and</c><00:00:35.190><c> we've</c><00:00:35.670><c> already</c><00:00:35.850><c> seen</c><00:00:36.329><c> the</c>

00:00:36.530 --> 00:00:36.540 align:start position:0%
hypothesis and we've already seen the
 

00:00:36.540 --> 00:00:39.530 align:start position:0%
hypothesis and we've already seen the
example<00:00:37.079><c> of</c><00:00:37.350><c> how</c><00:00:37.590><c> a</c><00:00:37.620><c> hypothesis</c><00:00:38.430><c> can</c><00:00:39.000><c> over</c><00:00:39.329><c> fit</c>

00:00:39.530 --> 00:00:39.540 align:start position:0%
example of how a hypothesis can over fit
 

00:00:39.540 --> 00:00:43.220 align:start position:0%
example of how a hypothesis can over fit
and<00:00:40.550><c> therefore</c><00:00:41.550><c> fail</c><00:00:41.820><c> to</c><00:00:42.270><c> generalize</c><00:00:42.930><c> to</c><00:00:43.200><c> new</c>

00:00:43.220 --> 00:00:43.230 align:start position:0%
and therefore fail to generalize to new
 

00:00:43.230 --> 00:00:45.020 align:start position:0%
and therefore fail to generalize to new
examples<00:00:43.379><c> that</c><00:00:44.190><c> are</c><00:00:44.280><c> not</c><00:00:44.430><c> in</c><00:00:44.610><c> the</c><00:00:44.700><c> training</c>

00:00:45.020 --> 00:00:45.030 align:start position:0%
examples that are not in the training
 

00:00:45.030 --> 00:00:48.470 align:start position:0%
examples that are not in the training
set<00:00:45.320><c> so</c><00:00:46.320><c> how</c><00:00:46.770><c> do</c><00:00:46.829><c> you</c><00:00:46.980><c> tell</c><00:00:47.280><c> if</c><00:00:47.640><c> the</c><00:00:47.760><c> hypothesis</c>

00:00:48.470 --> 00:00:48.480 align:start position:0%
set so how do you tell if the hypothesis
 

00:00:48.480 --> 00:00:49.639 align:start position:0%
set so how do you tell if the hypothesis
might<00:00:48.780><c> be</c><00:00:48.899><c> overfitting</c>

00:00:49.639 --> 00:00:49.649 align:start position:0%
might be overfitting
 

00:00:49.649 --> 00:00:52.790 align:start position:0%
might be overfitting
in<00:00:49.890><c> this</c><00:00:50.520><c> simple</c><00:00:50.879><c> example</c><00:00:50.940><c> we</c><00:00:51.809><c> could</c><00:00:52.020><c> plot</c><00:00:52.440><c> the</c>

00:00:52.790 --> 00:00:52.800 align:start position:0%
in this simple example we could plot the
 

00:00:52.800 --> 00:00:55.250 align:start position:0%
in this simple example we could plot the
hypothesis<00:00:53.579><c> H</c><00:00:53.760><c> of</c><00:00:54.059><c> X</c><00:00:54.270><c> and</c><00:00:54.539><c> just</c><00:00:54.750><c> see</c><00:00:54.930><c> what's</c>

00:00:55.250 --> 00:00:55.260 align:start position:0%
hypothesis H of X and just see what's
 

00:00:55.260 --> 00:00:58.069 align:start position:0%
hypothesis H of X and just see what's
going<00:00:55.530><c> on</c><00:00:55.680><c> but</c><00:00:56.520><c> in</c><00:00:56.789><c> general</c><00:00:57.300><c> for</c><00:00:57.329><c> problems</c>

00:00:58.069 --> 00:00:58.079 align:start position:0%
going on but in general for problems
 

00:00:58.079 --> 00:01:00.049 align:start position:0%
going on but in general for problems
with<00:00:58.289><c> more</c><00:00:58.649><c> features</c><00:00:58.890><c> than</c><00:00:59.129><c> just</c><00:00:59.609><c> one</c><00:00:59.820><c> feature</c>

00:01:00.049 --> 00:01:00.059 align:start position:0%
with more features than just one feature
 

00:01:00.059 --> 00:01:02.090 align:start position:0%
with more features than just one feature
for<00:01:00.690><c> problems</c><00:01:01.140><c> with</c><00:01:01.320><c> a</c><00:01:01.350><c> large</c><00:01:01.680><c> number</c><00:01:02.039><c> of</c>

00:01:02.090 --> 00:01:02.100 align:start position:0%
for problems with a large number of
 

00:01:02.100 --> 00:01:04.939 align:start position:0%
for problems with a large number of
features<00:01:02.340><c> like</c><00:01:02.850><c> these</c><00:01:03.090><c> it</c><00:01:03.719><c> becomes</c><00:01:03.930><c> hard</c><00:01:04.619><c> or</c>

00:01:04.939 --> 00:01:04.949 align:start position:0%
features like these it becomes hard or
 

00:01:04.949 --> 00:01:07.670 align:start position:0%
features like these it becomes hard or
maybe<00:01:05.549><c> impossible</c><00:01:06.030><c> to</c><00:01:06.930><c> plot</c><00:01:07.229><c> what</c><00:01:07.590><c> the</c>

00:01:07.670 --> 00:01:07.680 align:start position:0%
maybe impossible to plot what the
 

00:01:07.680 --> 00:01:10.460 align:start position:0%
maybe impossible to plot what the
hypothesis<00:01:08.369><c> function</c><00:01:08.760><c> looks</c><00:01:08.970><c> like</c><00:01:09.060><c> and</c><00:01:09.390><c> so</c><00:01:10.140><c> we</c>

00:01:10.460 --> 00:01:10.470 align:start position:0%
hypothesis function looks like and so we
 

00:01:10.470 --> 00:01:12.020 align:start position:0%
hypothesis function looks like and so we
need<00:01:10.650><c> some</c><00:01:10.890><c> other</c><00:01:11.070><c> way</c><00:01:11.250><c> to</c><00:01:11.280><c> evaluate</c><00:01:11.790><c> a</c>

00:01:12.020 --> 00:01:12.030 align:start position:0%
need some other way to evaluate a
 

00:01:12.030 --> 00:01:14.480 align:start position:0%
need some other way to evaluate a
hypothesis<00:01:12.780><c> the</c><00:01:13.350><c> standard</c><00:01:13.799><c> way</c><00:01:13.950><c> to</c><00:01:14.010><c> evaluate</c>

00:01:14.480 --> 00:01:14.490 align:start position:0%
hypothesis the standard way to evaluate
 

00:01:14.490 --> 00:01:16.969 align:start position:0%
hypothesis the standard way to evaluate
a<00:01:14.970><c> learned</c><00:01:15.270><c> hypothesis</c><00:01:16.049><c> is</c><00:01:16.350><c> as</c><00:01:16.530><c> follows</c>

00:01:16.969 --> 00:01:16.979 align:start position:0%
a learned hypothesis is as follows
 

00:01:16.979 --> 00:01:18.980 align:start position:0%
a learned hypothesis is as follows
suppose<00:01:17.640><c> we</c><00:01:17.970><c> have</c><00:01:18.119><c> a</c><00:01:18.150><c> data</c><00:01:18.240><c> set</c><00:01:18.689><c> like</c><00:01:18.869><c> this</c>

00:01:18.980 --> 00:01:18.990 align:start position:0%
suppose we have a data set like this
 

00:01:18.990 --> 00:01:21.350 align:start position:0%
suppose we have a data set like this
here<00:01:19.530><c> I've</c><00:01:19.740><c> just</c><00:01:19.979><c> shown</c><00:01:20.310><c> 10</c><00:01:20.790><c> training</c>

00:01:21.350 --> 00:01:21.360 align:start position:0%
here I've just shown 10 training
 

00:01:21.360 --> 00:01:23.330 align:start position:0%
here I've just shown 10 training
examples<00:01:21.869><c> but</c><00:01:22.110><c> of</c><00:01:22.170><c> course</c><00:01:22.290><c> usually</c><00:01:22.650><c> we</c><00:01:23.189><c> may</c>

00:01:23.330 --> 00:01:23.340 align:start position:0%
examples but of course usually we may
 

00:01:23.340 --> 00:01:25.429 align:start position:0%
examples but of course usually we may
have<00:01:23.580><c> dozens</c><00:01:24.479><c> or</c><00:01:24.689><c> hundreds</c><00:01:25.110><c> or</c><00:01:25.290><c> maybe</c>

00:01:25.429 --> 00:01:25.439 align:start position:0%
have dozens or hundreds or maybe
 

00:01:25.439 --> 00:01:27.890 align:start position:0%
have dozens or hundreds or maybe
thousands<00:01:26.100><c> of</c><00:01:26.250><c> training</c><00:01:26.549><c> examples</c><00:01:27.030><c> in</c><00:01:27.479><c> order</c>

00:01:27.890 --> 00:01:27.900 align:start position:0%
thousands of training examples in order
 

00:01:27.900 --> 00:01:29.330 align:start position:0%
thousands of training examples in order
to<00:01:28.080><c> make</c><00:01:28.229><c> sure</c><00:01:28.259><c> we</c><00:01:28.590><c> can</c><00:01:28.740><c> evaluate</c><00:01:29.009><c> our</c>

00:01:29.330 --> 00:01:29.340 align:start position:0%
to make sure we can evaluate our
 

00:01:29.340 --> 00:01:31.370 align:start position:0%
to make sure we can evaluate our
hypothesis<00:01:30.119><c> what</c><00:01:30.420><c> we're</c><00:01:30.570><c> going</c><00:01:30.720><c> to</c><00:01:30.869><c> do</c><00:01:31.049><c> is</c>

00:01:31.370 --> 00:01:31.380 align:start position:0%
hypothesis what we're going to do is
 

00:01:31.380 --> 00:01:34.810 align:start position:0%
hypothesis what we're going to do is
split<00:01:32.030><c> the</c><00:01:33.030><c> data</c><00:01:33.240><c> we</c><00:01:33.509><c> have</c><00:01:33.540><c> into</c><00:01:34.229><c> two</c><00:01:34.439><c> portions</c>

00:01:34.810 --> 00:01:34.820 align:start position:0%
split the data we have into two portions
 

00:01:34.820 --> 00:01:38.240 align:start position:0%
split the data we have into two portions
the<00:01:35.820><c> first</c><00:01:36.150><c> portion</c><00:01:36.479><c> is</c><00:01:36.930><c> going</c><00:01:37.320><c> to</c><00:01:37.470><c> be</c><00:01:37.680><c> our</c>

00:01:38.240 --> 00:01:38.250 align:start position:0%
the first portion is going to be our
 

00:01:38.250 --> 00:01:43.850 align:start position:0%
the first portion is going to be our
usual<00:01:38.700><c> training</c><00:01:39.479><c> set</c><00:01:39.750><c> and</c><00:01:42.470><c> the</c><00:01:43.470><c> second</c>

00:01:43.850 --> 00:01:43.860 align:start position:0%
usual training set and the second
 

00:01:43.860 --> 00:01:47.050 align:start position:0%
usual training set and the second
portion<00:01:44.070><c> is</c><00:01:44.549><c> going</c><00:01:44.880><c> to</c><00:01:45.000><c> be</c><00:01:45.149><c> our</c><00:01:45.930><c> test</c><00:01:46.409><c> set</c><00:01:46.649><c> and</c>

00:01:47.050 --> 00:01:47.060 align:start position:0%
portion is going to be our test set and
 

00:01:47.060 --> 00:01:50.630 align:start position:0%
portion is going to be our test set and
a<00:01:48.060><c> pretty</c><00:01:48.329><c> typical</c><00:01:48.600><c> split</c><00:01:49.290><c> of</c><00:01:49.590><c> this</c><00:01:49.829><c> of</c><00:01:50.130><c> all</c>

00:01:50.630 --> 00:01:50.640 align:start position:0%
a pretty typical split of this of all
 

00:01:50.640 --> 00:01:52.609 align:start position:0%
a pretty typical split of this of all
the<00:01:50.850><c> data</c><00:01:51.030><c> we</c><00:01:51.270><c> have</c><00:01:51.509><c> into</c><00:01:51.780><c> a</c><00:01:51.930><c> training</c><00:01:52.290><c> set</c><00:01:52.590><c> and</c>

00:01:52.609 --> 00:01:52.619 align:start position:0%
the data we have into a training set and
 

00:01:52.619 --> 00:01:56.810 align:start position:0%
the data we have into a training set and
test<00:01:52.979><c> set</c><00:01:53.220><c> might</c><00:01:53.880><c> be</c><00:01:54.030><c> around</c><00:01:54.390><c> say</c><00:01:54.659><c> a</c><00:01:54.689><c> 70%</c><00:01:55.820><c> 30%</c>

00:01:56.810 --> 00:01:56.820 align:start position:0%
test set might be around say a 70% 30%
 

00:01:56.820 --> 00:01:59.460 align:start position:0%
test set might be around say a 70% 30%
slit<00:01:57.630><c> with</c><00:01:58.140><c> more</c><00:01:58.439><c> of</c><00:01:58.530><c> the</c><00:01:58.619><c> data</c><00:01:58.799><c> going</c><00:01:59.100><c> to</c>

00:01:59.460 --> 00:01:59.470 align:start position:0%
slit with more of the data going to
 

00:01:59.470 --> 00:02:02.910 align:start position:0%
slit with more of the data going to
and<00:02:00.160><c> relatively</c><00:02:00.730><c> less</c><00:02:01.000><c> the</c><00:02:01.300><c> test</c><00:02:01.600><c> set</c><00:02:01.810><c> and</c><00:02:02.080><c> so</c>

00:02:02.910 --> 00:02:02.920 align:start position:0%
and relatively less the test set and so
 

00:02:02.920 --> 00:02:06.180 align:start position:0%
and relatively less the test set and so
now<00:02:03.190><c> if</c><00:02:04.000><c> we</c><00:02:04.240><c> have</c><00:02:04.480><c> some</c><00:02:04.750><c> data</c><00:02:05.020><c> set</c><00:02:05.350><c> we</c><00:02:06.010><c> might</c>

00:02:06.180 --> 00:02:06.190 align:start position:0%
now if we have some data set we might
 

00:02:06.190 --> 00:02:09.450 align:start position:0%
now if we have some data set we might
assign<00:02:06.550><c> only</c><00:02:06.970><c> say</c><00:02:07.390><c> 70%</c><00:02:07.840><c> of</c><00:02:08.470><c> the</c><00:02:08.740><c> data</c><00:02:08.950><c> to</c><00:02:09.430><c> be</c>

00:02:09.450 --> 00:02:09.460 align:start position:0%
assign only say 70% of the data to be
 

00:02:09.460 --> 00:02:12.120 align:start position:0%
assign only say 70% of the data to be
our<00:02:09.670><c> training</c><00:02:10.060><c> set</c><00:02:10.300><c> where</c><00:02:10.660><c> here</c><00:02:10.930><c> M</c><00:02:11.290><c> is</c><00:02:11.530><c> as</c>

00:02:12.120 --> 00:02:12.130 align:start position:0%
our training set where here M is as
 

00:02:12.130 --> 00:02:14.070 align:start position:0%
our training set where here M is as
usual<00:02:12.580><c> on</c><00:02:12.820><c> number</c><00:02:13.090><c> of</c><00:02:13.180><c> training</c><00:02:13.510><c> examples</c><00:02:13.540><c> and</c>

00:02:14.070 --> 00:02:14.080 align:start position:0%
usual on number of training examples and
 

00:02:14.080 --> 00:02:17.520 align:start position:0%
usual on number of training examples and
the<00:02:14.860><c> remainder</c><00:02:15.490><c> of</c><00:02:15.520><c> our</c><00:02:16.000><c> data</c><00:02:16.330><c> might</c><00:02:17.170><c> then</c><00:02:17.350><c> be</c>

00:02:17.520 --> 00:02:17.530 align:start position:0%
the remainder of our data might then be
 

00:02:17.530 --> 00:02:19.410 align:start position:0%
the remainder of our data might then be
assigned<00:02:17.830><c> to</c><00:02:18.190><c> become</c><00:02:18.520><c> our</c><00:02:18.700><c> test</c><00:02:18.940><c> sets</c><00:02:19.210><c> and</c>

00:02:19.410 --> 00:02:19.420 align:start position:0%
assigned to become our test sets and
 

00:02:19.420 --> 00:02:21.690 align:start position:0%
assigned to become our test sets and
here<00:02:19.810><c> I'm</c><00:02:20.020><c> going</c><00:02:20.230><c> to</c><00:02:20.320><c> use</c><00:02:20.380><c> the</c><00:02:20.800><c> notation</c><00:02:20.950><c> M</c>

00:02:21.690 --> 00:02:21.700 align:start position:0%
here I'm going to use the notation M
 

00:02:21.700 --> 00:02:25.050 align:start position:0%
here I'm going to use the notation M
subscript<00:02:22.390><c> test</c><00:02:22.890><c> denote</c><00:02:23.890><c> to</c><00:02:24.340><c> denote</c><00:02:24.700><c> the</c>

00:02:25.050 --> 00:02:25.060 align:start position:0%
subscript test denote to denote the
 

00:02:25.060 --> 00:02:29.220 align:start position:0%
subscript test denote to denote the
number<00:02:25.090><c> of</c><00:02:25.510><c> test</c><00:02:26.110><c> examples</c><00:02:26.290><c> and</c><00:02:27.780><c> so</c><00:02:28.780><c> in</c>

00:02:29.220 --> 00:02:29.230 align:start position:0%
number of test examples and so in
 

00:02:29.230 --> 00:02:32.340 align:start position:0%
number of test examples and so in
general<00:02:29.470><c> this</c><00:02:30.450><c> subscript</c><00:02:31.450><c> test</c><00:02:31.750><c> is</c><00:02:31.990><c> going</c><00:02:32.200><c> to</c>

00:02:32.340 --> 00:02:32.350 align:start position:0%
general this subscript test is going to
 

00:02:32.350 --> 00:02:34.590 align:start position:0%
general this subscript test is going to
denote<00:02:32.650><c> examples</c><00:02:33.580><c> they</c><00:02:33.760><c> come</c><00:02:34.030><c> from</c><00:02:34.180><c> my</c><00:02:34.330><c> test</c>

00:02:34.590 --> 00:02:34.600 align:start position:0%
denote examples they come from my test
 

00:02:34.600 --> 00:02:38.449 align:start position:0%
denote examples they come from my test
set<00:02:34.840><c> so</c><00:02:35.080><c> that</c><00:02:35.220><c> x1</c><00:02:36.220><c> subscript</c><00:02:36.850><c> test</c><00:02:37.090><c> comma</c><00:02:38.050><c> y1</c>

00:02:38.449 --> 00:02:38.459 align:start position:0%
set so that x1 subscript test comma y1
 

00:02:38.459 --> 00:02:42.390 align:start position:0%
set so that x1 subscript test comma y1
subscript<00:02:39.459><c> test</c><00:02:39.700><c> is</c><00:02:40.360><c> my</c><00:02:40.690><c> first</c><00:02:41.320><c> test</c><00:02:41.800><c> example</c>

00:02:42.390 --> 00:02:42.400 align:start position:0%
subscript test is my first test example
 

00:02:42.400 --> 00:02:44.580 align:start position:0%
subscript test is my first test example
which<00:02:42.670><c> I</c><00:02:42.910><c> guess</c><00:02:43.120><c> in</c><00:02:43.300><c> this</c><00:02:43.450><c> example</c><00:02:43.780><c> might</c><00:02:44.560><c> be</c>

00:02:44.580 --> 00:02:44.590 align:start position:0%
which I guess in this example might be
 

00:02:44.590 --> 00:02:47.280 align:start position:0%
which I guess in this example might be
this<00:02:44.860><c> example</c><00:02:45.250><c> over</c><00:02:45.550><c> here</c>

00:02:47.280 --> 00:02:47.290 align:start position:0%
this example over here
 

00:02:47.290 --> 00:02:50.309 align:start position:0%
this example over here
so<00:02:48.069><c> a</c><00:02:48.370><c> fairly</c><00:02:49.000><c> typical</c><00:02:49.180><c> procedure</c><00:02:49.870><c> for</c>

00:02:50.309 --> 00:02:50.319 align:start position:0%
so a fairly typical procedure for
 

00:02:50.319 --> 00:02:52.050 align:start position:0%
so a fairly typical procedure for
training<00:02:50.769><c> and</c><00:02:50.980><c> testing</c><00:02:51.430><c> a</c><00:02:51.670><c> learning</c>

00:02:52.050 --> 00:02:52.060 align:start position:0%
training and testing a learning
 

00:02:52.060 --> 00:02:54.149 align:start position:0%
training and testing a learning
algorithm<00:02:52.299><c> may</c><00:02:52.629><c> be</c><00:02:52.720><c> linear</c><00:02:53.140><c> regression</c><00:02:53.590><c> would</c>

00:02:54.149 --> 00:02:54.159 align:start position:0%
algorithm may be linear regression would
 

00:02:54.159 --> 00:02:55.890 align:start position:0%
algorithm may be linear regression would
be<00:02:54.280><c> to</c><00:02:54.459><c> first</c><00:02:54.730><c> learn</c><00:02:55.000><c> the</c><00:02:55.209><c> parameter</c><00:02:55.720><c> vector</c>

00:02:55.890 --> 00:02:55.900 align:start position:0%
be to first learn the parameter vector
 

00:02:55.900 --> 00:02:58.440 align:start position:0%
be to first learn the parameter vector
from<00:02:56.739><c> the</c><00:02:56.920><c> training</c><00:02:57.310><c> data</c><00:02:57.489><c> here</c><00:02:58.000><c> the</c><00:02:58.120><c> training</c>

00:02:58.440 --> 00:02:58.450 align:start position:0%
from the training data here the training
 

00:02:58.450 --> 00:03:01.800 align:start position:0%
from the training data here the training
data<00:02:58.659><c> is</c><00:02:58.810><c> only</c><00:02:59.230><c> that</c><00:02:59.560><c> first</c><00:02:59.920><c> you</c><00:03:00.370><c> know</c><00:03:00.689><c> 70%</c><00:03:01.689><c> of</c>

00:03:01.800 --> 00:03:01.810 align:start position:0%
data is only that first you know 70% of
 

00:03:01.810 --> 00:03:04.860 align:start position:0%
data is only that first you know 70% of
the<00:03:02.170><c> data</c><00:03:02.349><c> set</c><00:03:03.030><c> finally</c><00:03:04.030><c> one</c><00:03:04.360><c> last</c><00:03:04.390><c> detail</c>

00:03:04.860 --> 00:03:04.870 align:start position:0%
the data set finally one last detail
 

00:03:04.870 --> 00:03:07.559 align:start position:0%
the data set finally one last detail
whereas<00:03:05.650><c> here</c><00:03:06.159><c> I've</c><00:03:06.459><c> drawn</c><00:03:06.790><c> des</c><00:03:07.030><c> as</c><00:03:07.299><c> though</c>

00:03:07.559 --> 00:03:07.569 align:start position:0%
whereas here I've drawn des as though
 

00:03:07.569 --> 00:03:09.690 align:start position:0%
whereas here I've drawn des as though
the<00:03:07.750><c> first</c><00:03:07.959><c> 70%</c><00:03:08.709><c> goes</c><00:03:08.890><c> to</c><00:03:08.920><c> the</c><00:03:09.069><c> training</c><00:03:09.129><c> set</c>

00:03:09.690 --> 00:03:09.700 align:start position:0%
the first 70% goes to the training set
 

00:03:09.700 --> 00:03:12.630 align:start position:0%
the first 70% goes to the training set
and<00:03:09.940><c> the</c><00:03:10.030><c> last</c><00:03:10.120><c> 30%</c><00:03:10.420><c> to</c><00:03:11.170><c> the</c><00:03:11.290><c> test</c><00:03:11.560><c> set</c><00:03:11.739><c> if</c>

00:03:12.630 --> 00:03:12.640 align:start position:0%
and the last 30% to the test set if
 

00:03:12.640 --> 00:03:14.880 align:start position:0%
and the last 30% to the test set if
there<00:03:13.030><c> is</c><00:03:13.180><c> any</c><00:03:13.420><c> sort</c><00:03:13.870><c> of</c><00:03:14.079><c> ordering</c><00:03:14.500><c> to</c><00:03:14.769><c> the</c>

00:03:14.880 --> 00:03:14.890 align:start position:0%
there is any sort of ordering to the
 

00:03:14.890 --> 00:03:17.960 align:start position:0%
there is any sort of ordering to the
data<00:03:15.129><c> it</c><00:03:15.609><c> actually</c><00:03:15.730><c> better</c><00:03:16.180><c> to</c><00:03:16.720><c> send</c><00:03:17.470><c> a</c><00:03:17.650><c> random</c>

00:03:17.960 --> 00:03:17.970 align:start position:0%
data it actually better to send a random
 

00:03:17.970 --> 00:03:20.430 align:start position:0%
data it actually better to send a random
70%<00:03:18.970><c> of</c><00:03:19.090><c> your</c><00:03:19.239><c> data</c><00:03:19.420><c> than</c><00:03:19.810><c> the</c><00:03:19.900><c> training</c><00:03:20.230><c> set</c>

00:03:20.430 --> 00:03:20.440 align:start position:0%
70% of your data than the training set
 

00:03:20.440 --> 00:03:22.860 align:start position:0%
70% of your data than the training set
and<00:03:20.650><c> a</c><00:03:20.859><c> random</c><00:03:21.099><c> 30%</c><00:03:22.000><c> of</c><00:03:22.150><c> your</c><00:03:22.209><c> data</c><00:03:22.390><c> to</c><00:03:22.840><c> the</c>

00:03:22.860 --> 00:03:22.870 align:start position:0%
and a random 30% of your data to the
 

00:03:22.870 --> 00:03:25.319 align:start position:0%
and a random 30% of your data to the
test<00:03:23.200><c> set</c><00:03:23.409><c> so</c><00:03:23.799><c> if</c><00:03:24.310><c> your</c><00:03:24.430><c> data</c><00:03:24.640><c> were</c><00:03:24.849><c> already</c>

00:03:25.319 --> 00:03:25.329 align:start position:0%
test set so if your data were already
 

00:03:25.329 --> 00:03:27.149 align:start position:0%
test set so if your data were already
randomly<00:03:25.959><c> sorted</c><00:03:26.200><c> you</c><00:03:26.530><c> could</c><00:03:26.680><c> just</c><00:03:26.889><c> take</c><00:03:27.040><c> the</c>

00:03:27.149 --> 00:03:27.159 align:start position:0%
randomly sorted you could just take the
 

00:03:27.159 --> 00:03:30.839 align:start position:0%
randomly sorted you could just take the
first<00:03:27.190><c> 70%</c><00:03:27.760><c> and</c><00:03:28.269><c> last</c><00:03:29.019><c> 30%</c><00:03:29.829><c> but</c><00:03:30.310><c> if</c><00:03:30.489><c> your</c><00:03:30.639><c> data</c>

00:03:30.839 --> 00:03:30.849 align:start position:0%
first 70% and last 30% but if your data
 

00:03:30.849 --> 00:03:33.089 align:start position:0%
first 70% and last 30% but if your data
were<00:03:31.209><c> not</c><00:03:31.420><c> random</c><00:03:31.900><c> the</c><00:03:32.019><c> order</c><00:03:32.409><c> may</c><00:03:32.769><c> be</c><00:03:32.829><c> better</c>

00:03:33.089 --> 00:03:33.099 align:start position:0%
were not random the order may be better
 

00:03:33.099 --> 00:03:35.369 align:start position:0%
were not random the order may be better
to<00:03:33.549><c> randomly</c><00:03:34.000><c> shuffle</c><00:03:34.510><c> or</c><00:03:34.690><c> to</c><00:03:34.840><c> randomly</c>

00:03:35.369 --> 00:03:35.379 align:start position:0%
to randomly shuffle or to randomly
 

00:03:35.379 --> 00:03:37.110 align:start position:0%
to randomly shuffle or to randomly
reorder<00:03:35.620><c> the</c><00:03:36.159><c> examples</c><00:03:36.670><c> in</c><00:03:36.819><c> your</c><00:03:36.849><c> training</c>

00:03:37.110 --> 00:03:37.120 align:start position:0%
reorder the examples in your training
 

00:03:37.120 --> 00:03:39.210 align:start position:0%
reorder the examples in your training
set<00:03:37.450><c> before</c><00:03:38.200><c> you</c><00:03:38.409><c> know</c><00:03:38.530><c> sending</c><00:03:38.859><c> the</c><00:03:39.010><c> first</c>

00:03:39.210 --> 00:03:39.220 align:start position:0%
set before you know sending the first
 

00:03:39.220 --> 00:03:41.309 align:start position:0%
set before you know sending the first
studies<00:03:39.579><c> 70%</c><00:03:40.359><c> of</c><00:03:40.450><c> the</c><00:03:40.540><c> training</c><00:03:40.840><c> set</c><00:03:41.049><c> and</c><00:03:41.230><c> the</c>

00:03:41.309 --> 00:03:41.319 align:start position:0%
studies 70% of the training set and the
 

00:03:41.319 --> 00:03:44.550 align:start position:0%
studies 70% of the training set and the
last<00:03:41.620><c> 30%</c><00:03:41.920><c> of</c><00:03:42.609><c> the</c><00:03:42.700><c> test</c><00:03:42.909><c> set</c><00:03:43.120><c> here</c><00:03:43.959><c> then</c><00:03:44.260><c> is</c><00:03:44.500><c> a</c>

00:03:44.550 --> 00:03:44.560 align:start position:0%
last 30% of the test set here then is a
 

00:03:44.560 --> 00:03:47.039 align:start position:0%
last 30% of the test set here then is a
fairly<00:03:45.069><c> typical</c><00:03:45.370><c> procedure</c><00:03:46.120><c> for</c><00:03:46.810><c> how</c><00:03:46.989><c> you</c>

00:03:47.039 --> 00:03:47.049 align:start position:0%
fairly typical procedure for how you
 

00:03:47.049 --> 00:03:49.259 align:start position:0%
fairly typical procedure for how you
will<00:03:47.319><c> train</c><00:03:47.650><c> and</c><00:03:48.040><c> test</c><00:03:48.280><c> a</c><00:03:48.609><c> learning</c><00:03:48.970><c> algorithm</c>

00:03:49.259 --> 00:03:49.269 align:start position:0%
will train and test a learning algorithm
 

00:03:49.269 --> 00:03:51.930 align:start position:0%
will train and test a learning algorithm
maybe<00:03:49.720><c> linear</c><00:03:50.109><c> regression</c><00:03:50.590><c> first</c><00:03:51.370><c> you</c><00:03:51.609><c> learn</c>

00:03:51.930 --> 00:03:51.940 align:start position:0%
maybe linear regression first you learn
 

00:03:51.940 --> 00:03:54.150 align:start position:0%
maybe linear regression first you learn
the<00:03:52.000><c> parameters</c><00:03:52.359><c> theta</c><00:03:53.260><c> from</c><00:03:53.769><c> the</c><00:03:53.889><c> training</c>

00:03:54.150 --> 00:03:54.160 align:start position:0%
the parameters theta from the training
 

00:03:54.160 --> 00:03:56.369 align:start position:0%
the parameters theta from the training
set<00:03:54.280><c> so</c><00:03:54.760><c> you</c><00:03:54.819><c> minimize</c><00:03:55.090><c> the</c><00:03:55.510><c> usual</c><00:03:55.989><c> training</c>

00:03:56.369 --> 00:03:56.379 align:start position:0%
set so you minimize the usual training
 

00:03:56.379 --> 00:03:58.830 align:start position:0%
set so you minimize the usual training
error<00:03:56.560><c> objective</c><00:03:57.129><c> J</c><00:03:57.370><c> of</c><00:03:57.549><c> theta</c><00:03:57.579><c> where</c><00:03:58.540><c> J</c><00:03:58.720><c> of</c>

00:03:58.830 --> 00:03:58.840 align:start position:0%
error objective J of theta where J of
 

00:03:58.840 --> 00:04:02.039 align:start position:0%
error objective J of theta where J of
theta<00:03:58.870><c> here</c><00:03:59.379><c> was</c><00:03:59.709><c> defined</c><00:04:00.160><c> using</c><00:04:00.639><c> that</c><00:04:00.849><c> 70%</c><00:04:01.720><c> of</c>

00:04:02.039 --> 00:04:02.049 align:start position:0%
theta here was defined using that 70% of
 

00:04:02.049 --> 00:04:04.229 align:start position:0%
theta here was defined using that 70% of
all<00:04:02.470><c> the</c><00:04:02.769><c> data</c><00:04:02.949><c> you</c><00:04:03.160><c> have</c><00:04:03.190><c> says</c><00:04:03.730><c> only</c><00:04:04.000><c> the</c>

00:04:04.229 --> 00:04:04.239 align:start position:0%
all the data you have says only the
 

00:04:04.239 --> 00:04:07.530 align:start position:0%
all the data you have says only the
training<00:04:04.540><c> data</c><00:04:04.900><c> and</c><00:04:05.790><c> then</c><00:04:06.790><c> you</c><00:04:07.060><c> will</c><00:04:07.180><c> compute</c>

00:04:07.530 --> 00:04:07.540 align:start position:0%
training data and then you will compute
 

00:04:07.540 --> 00:04:09.509 align:start position:0%
training data and then you will compute
the<00:04:07.629><c> test</c><00:04:08.109><c> error</c><00:04:08.379><c> and</c><00:04:08.769><c> I'm</c><00:04:08.919><c> going</c><00:04:09.099><c> to</c><00:04:09.220><c> denote</c>

00:04:09.509 --> 00:04:09.519 align:start position:0%
the test error and I'm going to denote
 

00:04:09.519 --> 00:04:12.420 align:start position:0%
the test error and I'm going to denote
the<00:04:09.579><c> test</c><00:04:09.790><c> error</c><00:04:10.359><c> as</c><00:04:10.780><c> J</c><00:04:11.199><c> subscript</c><00:04:11.530><c> test</c><00:04:12.099><c> and</c>

00:04:12.420 --> 00:04:12.430 align:start position:0%
the test error as J subscript test and
 

00:04:12.430 --> 00:04:14.189 align:start position:0%
the test error as J subscript test and
so<00:04:13.299><c> what</c><00:04:13.449><c> you</c><00:04:13.569><c> do</c><00:04:13.720><c> is</c><00:04:13.840><c> you</c><00:04:13.959><c> take</c><00:04:14.139><c> your</c>

00:04:14.189 --> 00:04:14.199 align:start position:0%
so what you do is you take your
 

00:04:14.199 --> 00:04:16.229 align:start position:0%
so what you do is you take your
parameter<00:04:14.769><c> theta</c><00:04:15.370><c> that</c><00:04:15.790><c> you've</c><00:04:15.910><c> learned</c><00:04:16.150><c> from</c>

00:04:16.229 --> 00:04:16.239 align:start position:0%
parameter theta that you've learned from
 

00:04:16.239 --> 00:04:18.620 align:start position:0%
parameter theta that you've learned from
the<00:04:16.419><c> training</c><00:04:16.660><c> set</c><00:04:16.780><c> and</c><00:04:17.079><c> plug</c><00:04:17.709><c> it</c><00:04:17.889><c> in</c><00:04:17.979><c> here</c><00:04:18.370><c> and</c>

00:04:18.620 --> 00:04:18.630 align:start position:0%
the training set and plug it in here and
 

00:04:18.630 --> 00:04:22.350 align:start position:0%
the training set and plug it in here and
compute<00:04:19.630><c> your</c><00:04:19.959><c> test</c><00:04:20.289><c> set</c><00:04:20.560><c> error</c><00:04:20.799><c> which</c><00:04:21.699><c> I'm</c>

00:04:22.350 --> 00:04:22.360 align:start position:0%
compute your test set error which I'm
 

00:04:22.360 --> 00:04:26.070 align:start position:0%
compute your test set error which I'm
going<00:04:22.660><c> to</c><00:04:22.750><c> write</c><00:04:22.990><c> as</c><00:04:23.349><c> follows</c><00:04:24.720><c> so</c><00:04:25.720><c> this</c><00:04:25.930><c> is</c>

00:04:26.070 --> 00:04:26.080 align:start position:0%
going to write as follows so this is
 

00:04:26.080 --> 00:04:27.780 align:start position:0%
going to write as follows so this is
basically

00:04:27.780 --> 00:04:27.790 align:start position:0%
basically
 

00:04:27.790 --> 00:04:32.970 align:start position:0%
basically
the<00:04:28.270><c> average</c><00:04:29.370><c> square</c><00:04:30.370><c> error</c><00:04:31.380><c> has</c><00:04:32.380><c> measured</c><00:04:32.890><c> it</c>

00:04:32.970 --> 00:04:32.980 align:start position:0%
the average square error has measured it
 

00:04:32.980 --> 00:04:35.730 align:start position:0%
the average square error has measured it
on<00:04:33.190><c> your</c><00:04:33.520><c> test</c><00:04:33.670><c> set</c><00:04:34.140><c> it's</c><00:04:35.140><c> pretty</c><00:04:35.410><c> much</c><00:04:35.530><c> what</c>

00:04:35.730 --> 00:04:35.740 align:start position:0%
on your test set it's pretty much what
 

00:04:35.740 --> 00:04:37.470 align:start position:0%
on your test set it's pretty much what
you'd<00:04:35.770><c> expect</c><00:04:35.920><c> so</c><00:04:36.400><c> I've</c><00:04:36.520><c> run</c><00:04:36.850><c> every</c><00:04:37.120><c> test</c>

00:04:37.470 --> 00:04:37.480 align:start position:0%
you'd expect so I've run every test
 

00:04:37.480 --> 00:04:40.140 align:start position:0%
you'd expect so I've run every test
example<00:04:38.080><c> through</c><00:04:38.410><c> your</c><00:04:38.590><c> hypothesis</c><00:04:39.370><c> with</c>

00:04:40.140 --> 00:04:40.150 align:start position:0%
example through your hypothesis with
 

00:04:40.150 --> 00:04:42.960 align:start position:0%
example through your hypothesis with
parameter<00:04:40.690><c> theta</c><00:04:40.930><c> and</c><00:04:41.350><c> just</c><00:04:41.950><c> measure</c><00:04:42.190><c> the</c>

00:04:42.960 --> 00:04:42.970 align:start position:0%
parameter theta and just measure the
 

00:04:42.970 --> 00:04:46.080 align:start position:0%
parameter theta and just measure the
squared<00:04:43.660><c> error</c><00:04:43.960><c> the</c><00:04:44.710><c> your</c><00:04:44.860><c> hypothesis</c><00:04:45.550><c> has</c><00:04:45.730><c> on</c>

00:04:46.080 --> 00:04:46.090 align:start position:0%
squared error the your hypothesis has on
 

00:04:46.090 --> 00:04:50.400 align:start position:0%
squared error the your hypothesis has on
your<00:04:46.390><c> M</c><00:04:46.750><c> subscript</c><00:04:47.140><c> test</c><00:04:47.880><c> test</c><00:04:48.880><c> examples</c><00:04:49.420><c> and</c>

00:04:50.400 --> 00:04:50.410 align:start position:0%
your M subscript test test examples and
 

00:04:50.410 --> 00:04:52.950 align:start position:0%
your M subscript test test examples and
of<00:04:50.650><c> course</c><00:04:50.920><c> this</c><00:04:51.220><c> is</c><00:04:51.460><c> the</c><00:04:51.700><c> definition</c><00:04:51.970><c> of</c><00:04:52.720><c> the</c>

00:04:52.950 --> 00:04:52.960 align:start position:0%
of course this is the definition of the
 

00:04:52.960 --> 00:04:56.370 align:start position:0%
of course this is the definition of the
test<00:04:53.920><c> set</c><00:04:54.130><c> error</c><00:04:54.310><c> if</c><00:04:54.970><c> we</c><00:04:55.030><c> are</c><00:04:55.480><c> using</c><00:04:55.720><c> linear</c>

00:04:56.370 --> 00:04:56.380 align:start position:0%
test set error if we are using linear
 

00:04:56.380 --> 00:04:59.070 align:start position:0%
test set error if we are using linear
regression<00:04:56.410><c> and</c><00:04:57.190><c> using</c><00:04:58.000><c> this</c><00:04:58.210><c> squared</c><00:04:58.810><c> error</c>

00:04:59.070 --> 00:04:59.080 align:start position:0%
regression and using this squared error
 

00:04:59.080 --> 00:05:08.130 align:start position:0%
regression and using this squared error
metric<00:05:05.820><c> how</c><00:05:06.820><c> about</c><00:05:07.090><c> if</c><00:05:07.300><c> we</c><00:05:07.330><c> were</c><00:05:07.630><c> doing</c><00:05:07.780><c> a</c>

00:05:08.130 --> 00:05:08.140 align:start position:0%
metric how about if we were doing a
 

00:05:08.140 --> 00:05:10.620 align:start position:0%
metric how about if we were doing a
classification<00:05:08.650><c> problem</c><00:05:09.070><c> and</c><00:05:09.760><c> say</c><00:05:10.180><c> using</c>

00:05:10.620 --> 00:05:10.630 align:start position:0%
classification problem and say using
 

00:05:10.630 --> 00:05:13.800 align:start position:0%
classification problem and say using
logistic<00:05:11.080><c> regression</c><00:05:11.740><c> instead</c><00:05:11.890><c> in</c><00:05:12.510><c> that</c><00:05:13.510><c> case</c>

00:05:13.800 --> 00:05:13.810 align:start position:0%
logistic regression instead in that case
 

00:05:13.810 --> 00:05:16.470 align:start position:0%
logistic regression instead in that case
the<00:05:14.260><c> procedure</c><00:05:14.560><c> for</c><00:05:15.340><c> training</c><00:05:15.880><c> and</c><00:05:16.000><c> testing</c>

00:05:16.470 --> 00:05:16.480 align:start position:0%
the procedure for training and testing
 

00:05:16.480 --> 00:05:18.270 align:start position:0%
the procedure for training and testing
say<00:05:16.870><c> logistic</c><00:05:17.380><c> regression</c><00:05:17.860><c> is</c><00:05:17.980><c> pretty</c>

00:05:18.270 --> 00:05:18.280 align:start position:0%
say logistic regression is pretty
 

00:05:18.280 --> 00:05:20.340 align:start position:0%
say logistic regression is pretty
similar<00:05:18.580><c> first</c><00:05:19.570><c> we</c><00:05:19.750><c> will</c><00:05:19.870><c> learn</c><00:05:20.110><c> the</c>

00:05:20.340 --> 00:05:20.350 align:start position:0%
similar first we will learn the
 

00:05:20.350 --> 00:05:22.170 align:start position:0%
similar first we will learn the
parameters<00:05:20.950><c> from</c><00:05:21.160><c> the</c><00:05:21.250><c> training</c><00:05:21.670><c> data</c><00:05:21.850><c> that</c>

00:05:22.170 --> 00:05:22.180 align:start position:0%
parameters from the training data that
 

00:05:22.180 --> 00:05:24.930 align:start position:0%
parameters from the training data that
first<00:05:22.630><c> 70%</c><00:05:23.170><c> of</c><00:05:23.590><c> the</c><00:05:23.710><c> data</c><00:05:23.920><c> and</c><00:05:24.400><c> then</c><00:05:24.640><c> they</c><00:05:24.790><c> will</c>

00:05:24.930 --> 00:05:24.940 align:start position:0%
first 70% of the data and then they will
 

00:05:24.940 --> 00:05:27.630 align:start position:0%
first 70% of the data and then they will
compute<00:05:25.480><c> the</c><00:05:25.510><c> test</c><00:05:26.140><c> error</c><00:05:26.380><c> as</c><00:05:26.740><c> follows</c><00:05:27.220><c> is</c><00:05:27.490><c> the</c>

00:05:27.630 --> 00:05:27.640 align:start position:0%
compute the test error as follows is the
 

00:05:27.640 --> 00:05:30.150 align:start position:0%
compute the test error as follows is the
same<00:05:27.880><c> objective</c><00:05:28.390><c> function</c><00:05:28.810><c> as</c><00:05:29.020><c> we</c><00:05:29.500><c> always</c><00:05:29.920><c> use</c>

00:05:30.150 --> 00:05:30.160 align:start position:0%
same objective function as we always use
 

00:05:30.160 --> 00:05:32.520 align:start position:0%
same objective function as we always use
for<00:05:30.400><c> logistic</c><00:05:30.880><c> regression</c><00:05:31.360><c> except</c><00:05:32.170><c> that</c><00:05:32.350><c> now</c>

00:05:32.520 --> 00:05:32.530 align:start position:0%
for logistic regression except that now
 

00:05:32.530 --> 00:05:35.480 align:start position:0%
for logistic regression except that now
is<00:05:32.770><c> defined</c><00:05:33.190><c> using</c><00:05:33.460><c> our</c><00:05:33.880><c> M</c><00:05:34.180><c> subscript</c><00:05:34.750><c> test</c>

00:05:35.480 --> 00:05:35.490 align:start position:0%
is defined using our M subscript test
 

00:05:35.490 --> 00:05:38.700 align:start position:0%
is defined using our M subscript test
test<00:05:36.490><c> examples</c><00:05:36.610><c> while</c><00:05:37.600><c> this</c><00:05:37.810><c> definition</c><00:05:38.020><c> of</c>

00:05:38.700 --> 00:05:38.710 align:start position:0%
test examples while this definition of
 

00:05:38.710 --> 00:05:40.860 align:start position:0%
test examples while this definition of
the<00:05:38.920><c> test</c><00:05:39.100><c> set</c><00:05:39.220><c> error</c><00:05:39.490><c> J</c><00:05:39.970><c> subscript</c><00:05:40.270><c> test</c><00:05:40.750><c> is</c>

00:05:40.860 --> 00:05:40.870 align:start position:0%
the test set error J subscript test is
 

00:05:40.870 --> 00:05:43.140 align:start position:0%
the test set error J subscript test is
perfectly<00:05:41.320><c> reasonable</c><00:05:41.880><c> sometimes</c><00:05:42.880><c> there's</c>

00:05:43.140 --> 00:05:43.150 align:start position:0%
perfectly reasonable sometimes there's
 

00:05:43.150 --> 00:05:45.900 align:start position:0%
perfectly reasonable sometimes there's
an<00:05:43.270><c> alternative</c><00:05:44.080><c> test</c><00:05:44.740><c> set</c><00:05:44.980><c> metric</c><00:05:45.550><c> that</c>

00:05:45.900 --> 00:05:45.910 align:start position:0%
an alternative test set metric that
 

00:05:45.910 --> 00:05:48.090 align:start position:0%
an alternative test set metric that
might<00:05:46.240><c> be</c><00:05:46.420><c> easier</c><00:05:46.810><c> to</c><00:05:46.990><c> interpret</c><00:05:47.320><c> and</c><00:05:47.890><c> that's</c>

00:05:48.090 --> 00:05:48.100 align:start position:0%
might be easier to interpret and that's
 

00:05:48.100 --> 00:05:50.280 align:start position:0%
might be easier to interpret and that's
the<00:05:48.280><c> miss</c><00:05:48.730><c> classification</c><00:05:49.570><c> error</c><00:05:49.840><c> it's</c><00:05:50.140><c> also</c>

00:05:50.280 --> 00:05:50.290 align:start position:0%
the miss classification error it's also
 

00:05:50.290 --> 00:05:52.260 align:start position:0%
the miss classification error it's also
called<00:05:50.620><c> the</c><00:05:50.830><c> zero</c><00:05:51.220><c> one</c><00:05:51.460><c> miss</c><00:05:51.640><c> classification</c>

00:05:52.260 --> 00:05:52.270 align:start position:0%
called the zero one miss classification
 

00:05:52.270 --> 00:05:55.020 align:start position:0%
called the zero one miss classification
error<00:05:52.480><c> with</c><00:05:53.140><c> zero</c><00:05:53.500><c> one</c><00:05:53.710><c> denoting</c><00:05:54.310><c> that</c><00:05:54.550><c> you</c>

00:05:55.020 --> 00:05:55.030 align:start position:0%
error with zero one denoting that you
 

00:05:55.030 --> 00:05:57.120 align:start position:0%
error with zero one denoting that you
either<00:05:55.240><c> get</c><00:05:55.720><c> an</c><00:05:55.900><c> example</c><00:05:56.230><c> right</c><00:05:56.590><c> or</c><00:05:56.860><c> you</c><00:05:56.980><c> get</c>

00:05:57.120 --> 00:05:57.130 align:start position:0%
either get an example right or you get
 

00:05:57.130 --> 00:06:00.270 align:start position:0%
either get an example right or you get
an<00:05:57.250><c> example</c><00:05:57.580><c> wrong</c><00:05:57.970><c> here's</c><00:05:58.900><c> what</c><00:05:59.080><c> I</c><00:05:59.110><c> mean</c><00:05:59.380><c> let</c>

00:06:00.270 --> 00:06:00.280 align:start position:0%
an example wrong here's what I mean let
 

00:06:00.280 --> 00:06:03.860 align:start position:0%
an example wrong here's what I mean let
me<00:06:00.310><c> define</c><00:06:00.730><c> the</c><00:06:01.090><c> error</c><00:06:01.300><c> of</c><00:06:01.810><c> a</c><00:06:02.500><c> prediction</c><00:06:02.530><c> that</c>

00:06:03.860 --> 00:06:03.870 align:start position:0%
me define the error of a prediction that
 

00:06:03.870 --> 00:06:10.560 align:start position:0%
me define the error of a prediction that
is<00:06:04.870><c> H</c><00:06:05.050><c> of</c><00:06:05.080><c> X</c><00:06:05.580><c> and</c><00:06:06.580><c> given</c><00:06:06.880><c> the</c><00:06:07.090><c> label</c><00:06:07.300><c> Y</c><00:06:07.630><c> as</c><00:06:09.570><c> equal</c>

00:06:10.560 --> 00:06:10.570 align:start position:0%
is H of X and given the label Y as equal
 

00:06:10.570 --> 00:06:14.610 align:start position:0%
is H of X and given the label Y as equal
to<00:06:10.750><c> one</c><00:06:11.020><c> if</c><00:06:11.880><c> my</c><00:06:12.880><c> hypothesis</c><00:06:13.720><c> outputs</c><00:06:14.080><c> a</c><00:06:14.590><c> value</c>

00:06:14.610 --> 00:06:14.620 align:start position:0%
to one if my hypothesis outputs a value
 

00:06:14.620 --> 00:06:17.520 align:start position:0%
to one if my hypothesis outputs a value
greater<00:06:15.340><c> than</c><00:06:15.490><c> equal</c><00:06:15.880><c> to</c><00:06:15.910><c> five</c><00:06:16.270><c> and</c><00:06:16.570><c> Y</c><00:06:17.470><c> is</c>

00:06:17.520 --> 00:06:17.530 align:start position:0%
greater than equal to five and Y is
 

00:06:17.530 --> 00:06:18.920 align:start position:0%
greater than equal to five and Y is
equal<00:06:17.740><c> to</c><00:06:17.950><c> zero</c>

00:06:18.920 --> 00:06:18.930 align:start position:0%
equal to zero
 

00:06:18.930 --> 00:06:21.280 align:start position:0%
equal to zero
or

00:06:21.280 --> 00:06:21.290 align:start position:0%
or
 

00:06:21.290 --> 00:06:24.850 align:start position:0%
or
if<00:06:22.270><c> my</c><00:06:23.270><c> hypothesis</c><00:06:23.960><c> outputs</c><00:06:24.110><c> a</c><00:06:24.380><c> value</c><00:06:24.410><c> less</c>

00:06:24.850 --> 00:06:24.860 align:start position:0%
if my hypothesis outputs a value less
 

00:06:24.860 --> 00:06:27.970 align:start position:0%
if my hypothesis outputs a value less
than<00:06:24.890><c> 0.5</c><00:06:25.580><c> and</c><00:06:26.060><c> y</c><00:06:26.240><c> is</c><00:06:26.300><c> equal</c><00:06:26.630><c> to</c><00:06:26.660><c> 1</c><00:06:26.960><c> right</c><00:06:27.740><c> so</c>

00:06:27.970 --> 00:06:27.980 align:start position:0%
than 0.5 and y is equal to 1 right so
 

00:06:27.980 --> 00:06:29.800 align:start position:0%
than 0.5 and y is equal to 1 right so
both<00:06:28.190><c> of</c><00:06:28.340><c> these</c><00:06:28.460><c> cases</c><00:06:28.730><c> basically</c><00:06:29.300><c> correspond</c>

00:06:29.800 --> 00:06:29.810 align:start position:0%
both of these cases basically correspond
 

00:06:29.810 --> 00:06:33.250 align:start position:0%
both of these cases basically correspond
to<00:06:30.050><c> if</c><00:06:30.980><c> your</c><00:06:31.760><c> hypothesis</c><00:06:32.480><c> mislabeled</c><00:06:33.170><c> the</c>

00:06:33.250 --> 00:06:33.260 align:start position:0%
to if your hypothesis mislabeled the
 

00:06:33.260 --> 00:06:36.070 align:start position:0%
to if your hypothesis mislabeled the
example<00:06:33.740><c> assuming</c><00:06:34.490><c> you</c><00:06:34.700><c> threshold</c><00:06:35.270><c> it</c><00:06:35.420><c> at</c><00:06:35.540><c> 0.5</c>

00:06:36.070 --> 00:06:36.080 align:start position:0%
example assuming you threshold it at 0.5
 

00:06:36.080 --> 00:06:38.650 align:start position:0%
example assuming you threshold it at 0.5
so<00:06:36.350><c> either</c><00:06:37.010><c> thought</c><00:06:37.400><c> it</c><00:06:37.550><c> was</c><00:06:37.670><c> more</c><00:06:38.210><c> likely</c><00:06:38.510><c> to</c>

00:06:38.650 --> 00:06:38.660 align:start position:0%
so either thought it was more likely to
 

00:06:38.660 --> 00:06:41.110 align:start position:0%
so either thought it was more likely to
be<00:06:38.750><c> 1</c><00:06:38.960><c> but</c><00:06:39.320><c> there</c><00:06:39.410><c> was</c><00:06:39.530><c> actually</c><00:06:39.770><c> zero</c><00:06:40.100><c> or</c><00:06:40.430><c> your</c>

00:06:41.110 --> 00:06:41.120 align:start position:0%
be 1 but there was actually zero or your
 

00:06:41.120 --> 00:06:42.700 align:start position:0%
be 1 but there was actually zero or your
hypothesis<00:06:41.780><c> thought</c><00:06:41.960><c> that</c><00:06:42.110><c> was</c><00:06:42.230><c> more</c><00:06:42.410><c> likely</c>

00:06:42.700 --> 00:06:42.710 align:start position:0%
hypothesis thought that was more likely
 

00:06:42.710 --> 00:06:44.560 align:start position:0%
hypothesis thought that was more likely
with<00:06:42.920><c> zero</c><00:06:43.160><c> but</c><00:06:43.490><c> that</c><00:06:43.520><c> Labour</c><00:06:43.760><c> was</c><00:06:43.970><c> actually</c><00:06:44.360><c> 1</c>

00:06:44.560 --> 00:06:44.570 align:start position:0%
with zero but that Labour was actually 1
 

00:06:44.570 --> 00:06:48.670 align:start position:0%
with zero but that Labour was actually 1
and<00:06:45.370><c> otherwise</c><00:06:46.370><c> we</c><00:06:46.790><c> define</c><00:06:47.320><c> this</c><00:06:48.320><c> error</c>

00:06:48.670 --> 00:06:48.680 align:start position:0%
and otherwise we define this error
 

00:06:48.680 --> 00:06:52.540 align:start position:0%
and otherwise we define this error
function<00:06:49.010><c> to</c><00:06:49.430><c> be</c><00:06:49.550><c> 0</c><00:06:49.940><c> if</c><00:06:50.930><c> only</c><00:06:51.430><c> you</c><00:06:52.430><c> know</c>

00:06:52.540 --> 00:06:52.550 align:start position:0%
function to be 0 if only you know
 

00:06:52.550 --> 00:06:55.720 align:start position:0%
function to be 0 if only you know
hypothesis<00:06:53.210><c> basically</c><00:06:53.780><c> classified</c><00:06:54.730><c> example</c>

00:06:55.720 --> 00:06:55.730 align:start position:0%
hypothesis basically classified example
 

00:06:55.730 --> 00:06:59.680 align:start position:0%
hypothesis basically classified example
Y<00:06:55.880><c> correctly</c><00:06:56.800><c> we</c><00:06:57.800><c> could</c><00:06:58.010><c> then</c><00:06:58.480><c> define</c><00:06:59.480><c> the</c>

00:06:59.680 --> 00:06:59.690 align:start position:0%
Y correctly we could then define the
 

00:06:59.690 --> 00:07:01.860 align:start position:0%
Y correctly we could then define the
test<00:06:59.900><c> error</c><00:07:00.370><c> using</c><00:07:01.370><c> the</c><00:07:01.580><c> misclassification</c>

00:07:01.860 --> 00:07:01.870 align:start position:0%
test error using the misclassification
 

00:07:01.870 --> 00:07:07.300 align:start position:0%
test error using the misclassification
error<00:07:02.870><c> metric</c><00:07:03.410><c> to</c><00:07:03.650><c> be</c><00:07:04.300><c> one</c><00:07:05.300><c> of</c><00:07:05.420><c> M</c><00:07:05.720><c> tests</c><00:07:06.170><c> of</c><00:07:06.320><c> sum</c>

00:07:07.300 --> 00:07:07.310 align:start position:0%
error metric to be one of M tests of sum
 

00:07:07.310 --> 00:07:11.200 align:start position:0%
error metric to be one of M tests of sum
from<00:07:07.550><c> I</c><00:07:07.790><c> equals</c><00:07:08.420><c> 1</c><00:07:08.450><c> to</c><00:07:09.110><c> M</c><00:07:09.400><c> subscript</c><00:07:10.400><c> test</c><00:07:10.730><c> of</c>

00:07:11.200 --> 00:07:11.210 align:start position:0%
from I equals 1 to M subscript test of
 

00:07:11.210 --> 00:07:19.600 align:start position:0%
from I equals 1 to M subscript test of
the<00:07:11.990><c> error</c><00:07:12.200><c> of</c><00:07:12.680><c> each</c><00:07:13.810><c> of</c><00:07:15.250><c> my</c><00:07:16.250><c> tests</c><00:07:17.650><c> comma</c><00:07:18.650><c> Y</c>

00:07:19.600 --> 00:07:19.610 align:start position:0%
the error of each of my tests comma Y
 

00:07:19.610 --> 00:07:22.210 align:start position:0%
the error of each of my tests comma Y
and<00:07:20.300><c> so</c><00:07:20.510><c> that's</c><00:07:20.810><c> just</c><00:07:20.900><c> some</c><00:07:21.290><c> my</c><00:07:21.860><c> way</c><00:07:22.070><c> of</c>

00:07:22.210 --> 00:07:22.220 align:start position:0%
and so that's just some my way of
 

00:07:22.220 --> 00:07:24.430 align:start position:0%
and so that's just some my way of
writing<00:07:22.430><c> out</c><00:07:22.700><c> that</c><00:07:22.940><c> this</c><00:07:23.120><c> is</c><00:07:23.270><c> exactly</c><00:07:23.450><c> the</c>

00:07:24.430 --> 00:07:24.440 align:start position:0%
writing out that this is exactly the
 

00:07:24.440 --> 00:07:27.280 align:start position:0%
writing out that this is exactly the
fraction<00:07:25.070><c> of</c><00:07:25.310><c> the</c><00:07:25.880><c> examples</c><00:07:26.480><c> in</c><00:07:26.690><c> my</c><00:07:26.810><c> test</c><00:07:27.110><c> set</c>

00:07:27.280 --> 00:07:27.290 align:start position:0%
fraction of the examples in my test set
 

00:07:27.290 --> 00:07:31.570 align:start position:0%
fraction of the examples in my test set
that<00:07:28.070><c> my</c><00:07:28.220><c> hypothesis</c><00:07:28.970><c> has</c><00:07:29.240><c> mislabeled</c><00:07:30.370><c> and</c><00:07:31.370><c> so</c>

00:07:31.570 --> 00:07:31.580 align:start position:0%
that my hypothesis has mislabeled and so
 

00:07:31.580 --> 00:07:33.190 align:start position:0%
that my hypothesis has mislabeled and so
that's<00:07:31.880><c> the</c><00:07:32.000><c> definition</c><00:07:32.150><c> of</c><00:07:32.780><c> the</c><00:07:32.900><c> test</c><00:07:33.080><c> set</c>

00:07:33.190 --> 00:07:33.200 align:start position:0%
that's the definition of the test set
 

00:07:33.200 --> 00:07:35.260 align:start position:0%
that's the definition of the test set
error<00:07:33.320><c> using</c><00:07:33.920><c> the</c><00:07:34.130><c> misclassification</c><00:07:34.280><c> error</c>

00:07:35.260 --> 00:07:35.270 align:start position:0%
error using the misclassification error
 

00:07:35.270 --> 00:07:37.990 align:start position:0%
error using the misclassification error
or<00:07:35.900><c> the</c><00:07:36.200><c> zero</c><00:07:36.560><c> one</c><00:07:36.830><c> misclassification</c><00:07:37.760><c> error</c>

00:07:37.990 --> 00:07:38.000 align:start position:0%
or the zero one misclassification error
 

00:07:38.000 --> 00:07:40.540 align:start position:0%
or the zero one misclassification error
metric<00:07:38.480><c> so</c><00:07:39.440><c> that's</c><00:07:39.920><c> the</c><00:07:40.070><c> standard</c><00:07:40.340><c> technique</c>

00:07:40.540 --> 00:07:40.550 align:start position:0%
metric so that's the standard technique
 

00:07:40.550 --> 00:07:43.050 align:start position:0%
metric so that's the standard technique
for<00:07:41.150><c> evaluating</c><00:07:41.690><c> how</c><00:07:42.260><c> good</c><00:07:42.560><c> a</c><00:07:42.770><c> learn</c>

00:07:43.050 --> 00:07:43.060 align:start position:0%
for evaluating how good a learn
 

00:07:43.060 --> 00:07:46.810 align:start position:0%
for evaluating how good a learn
hypothesis<00:07:44.060><c> in</c><00:07:44.810><c> the</c><00:07:45.350><c> next</c><00:07:45.650><c> video</c><00:07:45.950><c> we'll</c><00:07:46.520><c> adapt</c>

00:07:46.810 --> 00:07:46.820 align:start position:0%
hypothesis in the next video we'll adapt
 

00:07:46.820 --> 00:07:49.030 align:start position:0%
hypothesis in the next video we'll adapt
these<00:07:47.000><c> ideas</c><00:07:47.540><c> to</c><00:07:47.870><c> helping</c><00:07:48.230><c> us</c><00:07:48.410><c> do</c><00:07:48.620><c> things</c><00:07:48.860><c> like</c>

00:07:49.030 --> 00:07:49.040 align:start position:0%
these ideas to helping us do things like
 

00:07:49.040 --> 00:07:51.310 align:start position:0%
these ideas to helping us do things like
choose<00:07:49.430><c> what</c><00:07:50.120><c> features</c><00:07:50.570><c> like</c><00:07:50.900><c> degree</c><00:07:51.230><c> of</c>

00:07:51.310 --> 00:07:51.320 align:start position:0%
choose what features like degree of
 

00:07:51.320 --> 00:07:52.990 align:start position:0%
choose what features like degree of
polynomial<00:07:51.650><c> to</c><00:07:52.190><c> use</c><00:07:52.370><c> with</c><00:07:52.580><c> a</c><00:07:52.670><c> learning</c>

00:07:52.990 --> 00:07:53.000 align:start position:0%
polynomial to use with a learning
 

00:07:53.000 --> 00:07:54.850 align:start position:0%
polynomial to use with a learning
algorithm<00:07:53.270><c> or</c><00:07:53.840><c> choose</c><00:07:54.230><c> the</c><00:07:54.410><c> regularization</c>

00:07:54.850 --> 00:07:54.860 align:start position:0%
algorithm or choose the regularization
 

00:07:54.860 --> 00:07:58.690 align:start position:0%
algorithm or choose the regularization
parameter<00:07:55.370><c> for</c><00:07:56.090><c> learning</c><00:07:56.420><c> alpha</c>

